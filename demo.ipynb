{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c3388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "CUDA extension for cauchy multiplication not found. Install by going to extensions/cauchy/ and running `python setup.py install`. This should speed up end-to-end training by 10-50%\n",
      "Falling back on slow Cauchy kernel. Install at least one of pykeops or the CUDA extension for efficiency.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from concept_discovery.kmeans import kmeans_explore, kmeans_predict, plot_concepts\n",
    "from imputer.load import load_imputer\n",
    "\n",
    "from utils.utils import compute_significance, get_plot_drought, get_global, get_channel_wise\n",
    "\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40237aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\UCSD\\\\Fall 2024\\\\DSC 261\\\\Project\\\\CausalConceptTS', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\python39.zip', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\DLLs', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\lib', 'd:\\\\Anaconda\\\\envs\\\\deeplearning', '', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\lib\\\\site-packages', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\lib\\\\site-packages\\\\win32', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\lib\\\\site-packages\\\\win32\\\\lib', 'd:\\\\Anaconda\\\\envs\\\\deeplearning\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9c098",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d3b6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/ptbxl/x_train.npy')\n",
    "x_val = np.load('data/ptbxl/x_val.npy')\n",
    "x_test = np.load('data/ptbxl/x_test.npy')\n",
    "\n",
    "y_train = np.load('data/ptbxl/y_train.npy')\n",
    "y_val = np.load('data/ptbxl/y_val.npy')\n",
    "y_test = np.load('data/ptbxl/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee21217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle x and y together to maintain correspondence\n",
    "x_train_, y_train_ = shuffle(x_train, y_train, random_state=42)\n",
    "x_train_, y_train_ = x_train_[:1000], y_train_[:1000]\n",
    "\n",
    "x_test_, y_test_ = shuffle(x_test, y_test, random_state=42)\n",
    "x_test_, y_test_ = x_test_[:1000], y_test_[:1000]\n",
    "\n",
    "x_val_, y_val_ = shuffle(x_val, y_val, random_state=42)\n",
    "x_val_, y_val_ = x_val_[:1000], y_val_[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865e62ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save as .npy files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/ptbxl/x_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mx_train_\u001b[49m)\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/ptbxl/x_val.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, x_val_)\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/ptbxl/x_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, x_test_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_' is not defined"
     ]
    }
   ],
   "source": [
    "# Save as .npy files\n",
    "np.save('data/ptbxl/x_train.npy', x_train_)\n",
    "np.save('data/ptbxl/x_val.npy', x_val_)\n",
    "np.save('data/ptbxl/x_test.npy', x_test_)\n",
    "\n",
    "np.save('data/ptbxl/y_train.npy', y_train_)\n",
    "np.save('data/ptbxl/y_val.npy', y_val_)\n",
    "np.save('data/ptbxl/y_test.npy', y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4533f",
   "metadata": {},
   "source": [
    "### Concepts loading or discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bff41",
   "metadata": {},
   "source": [
    "If you have already defined concepts, you should load here them as \n",
    "'train_concepts', 'val_concepts', and 'test_concets' and skip the next concept discovery step.\n",
    "Each of these should be of the shape (N_concepts, N_samples, Lengh, Channels) and should be binary masks. e.g. 0's where the concept is present, and 1's where don't. (as per diffusion model requierement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----:clustering at 1 clusters:----\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ks=number of clusters to investigate, it will return a plot to make a final decision\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mkmeans_explore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32md:\\UCSD\\Fall 2024\\DSC 261\\Project\\CausalConceptTS\\concept_discovery\\kmeans.py:39\u001b[0m, in \u001b[0;36mkmeans_explore\u001b[1;34m(x_train, x_val, x_test, ks)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----:clustering at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m clusters:----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_2d\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fit to the dense array\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     inertia\u001b[38;5;241m.\u001b[39mappend(kmeans\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(inertia)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1171\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1170\u001b[0m     kmeans_single \u001b[38;5;241m=\u001b[39m _kmeans_single_lloyd\n\u001b[1;32m-> 1171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_mkl_vcomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m     kmeans_single \u001b[38;5;241m=\u001b[39m _kmeans_single_elkan\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1028\u001b[0m, in \u001b[0;36mKMeans._check_mkl_vcomp\u001b[1;34m(self, X, n_samples)\u001b[0m\n\u001b[0;32m   1026\u001b[0m active_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(n_samples \u001b[38;5;241m/\u001b[39m CHUNK_SIZE))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m active_threads \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_threads:\n\u001b[1;32m-> 1028\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[43mthreadpool_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m     has_vcomp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvcomp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [module[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules]\n\u001b[0;32m   1030\u001b[0m     has_mkl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m   1031\u001b[0m         (module[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal_api\u001b[39m\u001b[38;5;124m\"\u001b[39m], module\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreading_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m   1032\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules\n\u001b[0;32m   1033\u001b[0m     ]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\fixes.py:325\u001b[0m, in \u001b[0;36mthreadpool_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthreadpoolctl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreadpool_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:124\u001b[0m, in \u001b[0;36mthreadpool_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@_format_docstring\u001b[39m(USER_APIS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(_ALL_USER_APIS),\n\u001b[0;32m    108\u001b[0m                    INTERNAL_APIS\u001b[38;5;241m=\u001b[39m_ALL_INTERNAL_APIS)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mthreadpool_info\u001b[39m():\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the maximal number of threads for each detected library.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Return a list with all the supported modules that have been found. Each\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    In addition, each module may contain internal_api specific entries.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ThreadpoolInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ALL_USER_APIS\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtodicts()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_modules_with_enum_process_module_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_module_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[38;5;241m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# ks=number of clusters to investigate, it will return a plot to make a final decision\n",
    "\n",
    "kmeans_explore(x_train,x_val,x_test,ks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062fb78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9754, 248, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423ff45e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# k=desired number of concepts\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_concepts,val_concepts,test_concepts \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/drought/train_concepts.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, train_concepts)\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/drought/val_concepts.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, val_concepts)\n",
      "File \u001b[1;32md:\\UCSD\\Fall 2024\\DSC 261\\Project\\CausalConceptTS\\concept_discovery\\kmeans.py:89\u001b[0m, in \u001b[0;36mkmeans_predict\u001b[1;34m(x_train, x_val, x_test, k)\u001b[0m\n\u001b[0;32m     86\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m     87\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mfit(data_2d)\n\u001b[1;32m---> 89\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m     92\u001b[0m     m \u001b[38;5;241m=\u001b[39m _create_mask(x, i)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334\u001b[0m, in \u001b[0;36mKMeans.predict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1331\u001b[0m x_squared_norms \u001b[38;5;241m=\u001b[39m row_norms(X, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1332\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 1334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_labels_inertia_threadpool_limit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_centers_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:755\u001b[0m, in \u001b[0;36m_labels_inertia_threadpool_limit\u001b[1;34m(X, sample_weight, x_squared_norms, centers, n_threads)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_labels_inertia_threadpool_limit\u001b[39m(\n\u001b[0;32m    752\u001b[0m     X, sample_weight, x_squared_norms, centers, n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    753\u001b[0m ):\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;124;03m\"\"\"Same as _labels_inertia but in a threadpool_limits context.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mthreadpool_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    756\u001b[0m         labels, inertia \u001b[38;5;241m=\u001b[39m _labels_inertia(\n\u001b[0;32m    757\u001b[0m             X, sample_weight, x_squared_norms, centers, n_threads\n\u001b[0;32m    758\u001b[0m         )\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\fixes.py:314\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthreadpoolctl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreadpool_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_api\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(limits, user_api)\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_threadpool_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[43m_ThreadpoolInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m                          \u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_modules_with_enum_process_module_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_module_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[38;5;241m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# k=desired number of concepts\n",
    "\n",
    "train_concepts,val_concepts,test_concepts = kmeans_predict(x_train,x_val,x_test,k=6)\n",
    "\n",
    "np.save('data/drought/train_concepts.npy', train_concepts)\n",
    "np.save('data/drought/val_concepts.npy', val_concepts)\n",
    "np.save('data/drought/test_concepts.npy', test_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot your concepts\n",
    "\n",
    "max_length = x_test.shape[1] # length of the ts for plotting (can be smaller than the total)\n",
    "leadsn = [\"I\",\"II\",\"III\",\"aVR\",\"aVL\",\"aVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"] # name of your channels\n",
    "index = np.where(y_test==1)[0][0] # index of a class sample\n",
    "data = x_test # data to use (we used test for the index, so update accordly)\n",
    "concepts = test_concepts # concepts of the desired split (test again)\n",
    "save_fig = True \n",
    "savename = 'concepts.pdf'\n",
    "\n",
    "plot_concepts(max_length, leadsn, index, data, concepts, savefig=save_fig, savename=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbc76b",
   "metadata": {},
   "source": [
    "### Classifier model loading or training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8b4ac",
   "metadata": {},
   "source": [
    "In this section, you can either load the model of your choice and assign it in a variable named 'classifier' or train an S4 model as in our main experiments paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ba628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you data should be in 'data/'\n",
    "\n",
    "# Construct the command to run the script\n",
    "command = [\n",
    "    'python', 'classifier/main.py',\n",
    "    '--input-size', max_length,\n",
    "    '--architecture', 's4',\n",
    "    '--precision', 32,\n",
    "    '--s4-n', 8,\n",
    "    '--s4-h', 512,\n",
    "    '--batch-size', 32,\n",
    "    '--epochs', 20,\n",
    "    '--input-channels', len(leadsn)\n",
    "]\n",
    "\n",
    "# it will save your model as first version (if there isn't any already)\n",
    "subprocess.run(command, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e53bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model configuration\n",
    "with open('version_0/hparams.yaml') as f:\n",
    "    hparams = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "namespace = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and keep it in evaluation mode\n",
    "model = Main(hparams=namespace).cuda()\n",
    "model.load_weights_from_checkpoint('version_0/best_model.ckpt')\n",
    "classifier = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bbd7b",
   "metadata": {},
   "source": [
    "### Diffusion model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create configuration files, one for each model\n",
    "\n",
    "config_paths = []\n",
    "\n",
    "for setting in ['class','norm']:\n",
    "\n",
    "    config = {\n",
    "        \"diffusion_config\": {\n",
    "            \"T\": 200,\n",
    "            \"beta_0\": 0.0001,\n",
    "            \"beta_T\": 0.02\n",
    "        },\n",
    "        \"wavenet_config\": {\n",
    "            \"in_channels\": len(leadsn), \n",
    "            \"out_channels\": len(leadsn),\n",
    "            \"num_res_layers\": 36,\n",
    "            \"res_channels\": 256, \n",
    "            \"skip_channels\": 256,\n",
    "            \"diffusion_step_embed_dim_in\": 128,\n",
    "            \"diffusion_step_embed_dim_mid\": 512,\n",
    "            \"diffusion_step_embed_dim_out\": 512,\n",
    "            \"s4_lmax\": x_train.shape[1],\n",
    "            \"s4_d_state\": 64,\n",
    "            \"s4_dropout\": 0.0,\n",
    "            \"s4_bidirectional\": 1,\n",
    "            \"s4_layernorm\": 1\n",
    "        },\n",
    "        \"train_config\": {\n",
    "            \"output_directory\": f\"/imputer/results/{setting}\",\n",
    "            \"ckpt_iter\": \"max\",\n",
    "            \"iters_per_logging\": 100,\n",
    "            \"n_iters\": 10000,\n",
    "            \"learning_rate\": 2e-4,   \n",
    "            \"target_class\": setting\n",
    "        },\n",
    "        \"trainset_config\": {\n",
    "            \"segment_length\": x_train.shape[1]\n",
    "        },\n",
    "        \"gen_config\": {\n",
    "            \"output_directory\": f\"/imputer/results/{setting}\",\n",
    "            \"ckpt_path\": f\"/imputer/results/{setting}/\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the configuration to a JSON file\n",
    "    config_path = f'imputer/config_{setting}.json'\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    config_paths.append(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train each of the models\n",
    "\n",
    "for config_path in config_paths:\n",
    "    \n",
    "    command = [\n",
    "    'python', 'imputer/train.py',\n",
    "    '--config', config_path]\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc5e7a",
   "metadata": {},
   "source": [
    "### Diffusion model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e40f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_path in config_paths:\n",
    "    \n",
    "    imputer = load_imputer(path_json=config_path,\n",
    "                           ckpt_iter=10000)\n",
    "    \n",
    "    target_class = 'class'                                    \n",
    "    target_generations = 40\n",
    "\n",
    "    for mask_s, mask in zip(['A','B','C','D','E','F'], [test_concetps[0],\n",
    "                                                             test_concepts[1],\n",
    "                                                             test_concepts[2],\n",
    "                                                             test_concepts[3],\n",
    "                                                             test_concepts[4],\n",
    "                                                             test_concepts[5]]):\n",
    "        for g in range(1,target_generations+1):\n",
    "            generation =  sampling(net,\n",
    "                                  (len(x_test), x_test.shape[1], x_test.shape[2]),                                    \n",
    "                                  diffusion_hyperparams, \n",
    "                                  cond = torch.from_numpy(samples).permute(0,2,1).cuda().float(),\n",
    "                                  mask = torch.from_numpy(mask).permute(0,2,1).cuda().float())                                            \n",
    "\n",
    "            outfile = f'{target_disease}_{mask_s}_{g}.npy'                  \n",
    "            new_out = os.path.join(ckpt_path, outfile)\n",
    "            np.save(new_out, generation.detach().cpu().numpy())\n",
    "            print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce96dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40adc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6222a79",
   "metadata": {},
   "source": [
    "### Causal Concept Time Series Explainer (CausalConceptTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sig_dou_s, global_sig_doc_s = get_global(concepts=['A','B','C','D','E','F'], \n",
    "                                                target_generations=target_generations, \n",
    "                                                l_channels=x_test.shape[2])\n",
    "\n",
    "channel_sig_dou_s, channel_sig_doc_s = get_channel_wise(concepts=['A','B','C','D','E','F'],\n",
    "                                                        target_generations=target_generations, \n",
    "                                                        l_channels=x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694893f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot_drought(global_sig_doc_g, \n",
    "         global_sig_doc_s, \n",
    "         global_do0_c, \n",
    "         channel_sig_doc_g, \n",
    "         channel_sig_doc_s, \n",
    "         channel_do0_c, \n",
    "         channels=leadsn,\n",
    "        concepts=['A','B','C','D','E','F'],\n",
    "         'do(causal).pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d9dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1b90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
